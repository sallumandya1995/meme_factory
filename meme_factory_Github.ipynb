{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install fal_client fastapi python-dotenv uvicorn gradio openai"
      ],
      "metadata": {
        "id": "ca8mKG4Uac5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "def save_secrets(api_key, api_base, fal_key):\n",
        "    os.environ[\"API_KEY\"] = api_key\n",
        "    os.environ[\"API_BASE\"] = api_base\n",
        "    os.environ[\"FAL_KEY\"] = fal_key\n",
        "\n",
        "\n",
        "save_secrets(\n",
        "    api_key=\"sk-or-v1-\",   ### use openrouter api key\n",
        "    api_base=\"https://openrouter.ai/api/v1\",\n",
        "    fal_key=\"1a83aad3-18\"\n",
        ")\n",
        "\n",
        "print(os.environ.get(\"API_KEY\"))\n",
        "print(os.environ.get(\"API_BASE\"))\n",
        "print(os.environ.get(\"FAL_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfFHnb3caubW",
        "outputId": "ccdef8ff-1652-4059-c325-94fd89877400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n",
            "https://openrouter.ai/api/v1\n",
            "1a83aad3-1801-4b6f-ac1d-14a3c82d95f5:d2f493d1878b0859c2233d19a3701fd8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "libraries = ['fal_client', 'fastapi', 'python-dotenv', 'uvicorn', 'gradio', 'openai']\n",
        "\n",
        "for lib in libraries:\n",
        "    result = subprocess.run(['pip', 'show', lib], capture_output=True, text=True)\n",
        "    version = [line for line in result.stdout.split('\\n') if 'Version:' in line][0]\n",
        "    print(f\"{lib}: {version}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX_w3QPaoUx",
        "outputId": "bea133b9-f9ff-4d05-d3a0-ad64d7843a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fal_client: Version: 0.5.6\n",
            "fastapi: Version: 0.115.6\n",
            "python-dotenv: Version: 1.0.1\n",
            "uvicorn: Version: 0.34.0\n",
            "gradio: Version: 5.9.1\n",
            "openai: Version: 1.57.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import fal_client\n",
        "from pydantic import BaseModel\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "api_key = os.getenv('API_KEY')\n",
        "api_base = os.getenv('API_BASE')\n",
        "FAL_KEY = os.getenv('FAL_KEY')\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=api_base\n",
        ")\n",
        "\n",
        "model = \"google/gemini-flash-1.5\"\n",
        "\n",
        "class MemeRequest(BaseModel):\n",
        "    domain: str\n",
        "\n",
        "class MemeResponse(BaseModel):\n",
        "    image_url: str\n",
        "    top_text: str\n",
        "    bottom_text: str\n",
        "\n",
        "def generate_meme(domain: str) -> MemeResponse:\n",
        "    \"\"\"\n",
        "    Generates a meme based on the given domain.\n",
        "    This function is adapted from your FastAPI code.\n",
        "    \"\"\"\n",
        "    temperature = round(random.uniform(0.5, 0.9), 2)\n",
        "    print(f\"Temperature: {temperature}\")\n",
        "\n",
        "    user_content = (f\"Act like Non offensive meme maker. Always create different and unique funny memes \"\n",
        "                    f\"always remember stable diffusion cannot render text natively hence , write prompt just detailing the scene or image without text\"\n",
        "                    f\"Return meme details in below json format for topic {domain}\\n\\n\"\n",
        "                    \"{ \\\"stableDiffusionPrompt\\\": \\\" \\\", \\\"topText\\\": \\\"\\\", \\\"bottomText\\\": \\\"\\\" }\\n\\n\"\n",
        "                    \"Strictly just reply json no extra text\")\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful meme maker, who makes non offensive memes(Dont include Cat in memes)\"},\n",
        "            {\"role\": \"user\", \"content\": user_content}\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    result = chat_completion.choices[0].message.content\n",
        "\n",
        "    try:\n",
        "        meme_data = json.loads(result)\n",
        "    except json.JSONDecodeError:\n",
        "        json_match = re.search(r'```json\\s*(.*?)\\s*```', result, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_string = json_match.group(1)\n",
        "            meme_data = json.loads(json_string)\n",
        "        else:\n",
        "            raise ValueError(\"No valid JSON found in the response\")\n",
        "\n",
        "    print(\"Stable Diffusion Prompt:\", meme_data['stableDiffusionPrompt'])\n",
        "    print(\"Top Text:\", meme_data['topText'])\n",
        "    print(\"Bottom Text:\", meme_data['bottomText'])\n",
        "\n",
        "\n",
        "\n",
        "    handler = fal_client.submit(\n",
        "        \"fal-ai/flux/schnell\",\n",
        "        arguments={\n",
        "            \"prompt\": meme_data['stableDiffusionPrompt'],\n",
        "            \"image_size\": \"landscape_4_3\",\n",
        "            \"num_inference_steps\": 4,\n",
        "            \"num_images\": 1,\n",
        "            \"enable_safety_checker\": True\n",
        "        }\n",
        "    )\n",
        "\n",
        "    result = handler.get()\n",
        "    image_url = result['images'][0]['url']\n",
        "    print(\"Generated Image URL:\", image_url)\n",
        "\n",
        "    return MemeResponse(\n",
        "        top_text=meme_data['topText'],\n",
        "        image_url=image_url,\n",
        "        bottom_text=meme_data['bottomText']  )\n",
        "\n",
        "def generate_meme_gradio(domain):\n",
        "    \"\"\"\n",
        "    Wrapper function for Gradio interface.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        meme_response = generate_meme(domain)\n",
        "        print(meme_response.top_text, meme_response.image_url, meme_response.bottom_text)\n",
        "        return meme_response.top_text, meme_response.image_url, meme_response.bottom_text\n",
        "    except Exception as e:\n",
        "        return None, str(e), \"\"\n",
        "\n",
        "\n",
        "# # Create Gradio interface\n",
        "import gradio as gr\n",
        "\n",
        "# Example domains\n",
        "example_domains = [\n",
        "    'HR', 'Technology', 'AI', 'Machine Learning', 'Sales', 'Marketing',\n",
        "    'Remote Work', 'Coffee', 'Monday', 'Deadlines', 'Office Pranks', 'Tech Support',\n",
        "    'Social Media', 'Startup Life', 'Zoom Fails', 'Work-Life Balance', 'Coding',\n",
        "    'Data Privacy', 'Cybersecurity', 'Cloud Computing', 'Blockchain', 'IoT',\n",
        "    'Virtual Reality', 'Augmented Reality', 'Quantum Computing', '5G', 'AI Ethics'\n",
        "]\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=generate_meme_gradio,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"Enter your meme topic\",\n",
        "            placeholder=\"Type a topic or choose from examples below\",\n",
        "            info=\"Try topics like 'AI', 'Remote Work', or 'Tech Support'\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Top Text\"),\n",
        "        gr.Image(label=\"Generated Meme\"),\n",
        "        gr.Textbox(label=\"Bottom Text\")\n",
        "    ],\n",
        "    theme=gr.themes.Ocean(),\n",
        "    title=\"ðŸŽ¨ AI Meme Factory\",\n",
        "    description=\"\"\"\n",
        "    Welcome to the AI Meme Factory! World's First Generative meme Engine.\n",
        "    Generate unique, funny, and non-offensive memes using the power of AI.\n",
        "\n",
        "    ðŸ¤– Powered by:\n",
        "    - Gemini for creative text generation\n",
        "    - Flux for high-quality image generation\n",
        "\n",
        "    âœ¨ Features:\n",
        "    - Instant meme generation\n",
        "    - Professional and work-appropriate content\n",
        "    - Wide range of topics supported\n",
        "    \"\"\",\n",
        "    examples=[[domain] for domain in random.sample(example_domains, 6)],\n",
        "    allow_flagging=\"never\",\n",
        "    cache_examples=False\n",
        ")\n",
        "demo.launch(  share=True,   debug=True )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "ipI1_Y18gyNZ",
        "outputId": "6de85bee-f4df-442e-a2ad-3ccb2e574cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4e6465b6f4a9aa9b9e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4e6465b6f4a9aa9b9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature: 0.68\n",
            "Stable Diffusion Prompt: A person wearing AR glasses, superimposed holographic images of tools and instructions floating around them as they assemble a complex piece of furniture in a living room. The furniture is mostly assembled, showing progress.\n",
            "Top Text: Me trying to follow IKEA instructions\n",
            "Bottom Text: With Augmented Reality\n",
            "Generated Image URL: https://fal.media/files/penguin/IUJM8p_POzBXftRG1M3Xs.png\n",
            "Me trying to follow IKEA instructions https://fal.media/files/penguin/IUJM8p_POzBXftRG1M3Xs.png With Augmented Reality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YLjqNBmmLKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_68-GaixvV2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}